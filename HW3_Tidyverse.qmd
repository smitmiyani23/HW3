---
title: "ST558 HW3: Objects, Control Flow and Functions"
format: html
editor: visual
---

### Document Details

#### Author: *Smit Miyani*

#### Collaborators: *N/A*

#### Assignment: *HW3*

#### Date: *04JUN24*

#### Purpose

*General practice in working with `tidyverse` and database.*\

\

### Tasks

#### Task 1: Conceptual Questions

1.  If your working directory is `myfolder/homework/`, what *relative* path would you specify to get the file located at `myfolder/MyData.csv`?

    > To do this, we can use `../MyData.csv`

2.  What are the major benefits of using R projects?

    > R projects provides an environment for organizing files, managing and integrating with version control systems like git, which enhances productivity and collaboration in development and data analysis.

3.  What is git and what is github?

    > Git is a version control software that can track and modify changes in files and folders within a repository. Github is the online hosting platform for Git-based projects

4.  What are the two main differences between a tibble and a data.frame?

    > The two main differences between a tibble and a data.frame are:
    >
    > 1.  Tibbles only shows the first 10 rows and all columns that fit within the console width. They do not support row names. Data frames, on the other hand, typically print the entire dataset, which can be draining for large datasets.
    > 2.  Subsetting operations on tibbles are stricter than those on data frames, with case-insensitive column name matching and no default partial matching, reducing the risk of errors. But, data frames, allow for partial matching by default, which can lead to unexpected results.

5.  Rewrite the following nested function call using baseR's chaining operator: `arrange(filter(select(as_tibble(iris), starts_with("Petal"), Species), Petal.Length <1.55), Species)`

    > `iris |>`
    >
    > `as_tibble() |>`
    >
    > `select(starts_with("Petal"), Species) |>`
    >
    > `filter(Petal.Length < 1.55) |>`
    >
    > `arrange(Species)`

6.  What is meant by long format data and wide format data? Which do we generally prefer for statistical analysis?

    > -   **Long format data**: Each row represents a single observation, and each variable has its own column. It's good for handling repeated measurements or comparisons across different groups.
    >
    > -   **Wide format data**: Each row represents a subject, and variables may have multiple columns representing different categories. It's useful when each subject has only one observation or when comparing variables across subjects.
    >
    > For statistical analysis, we generally prefer long format data because it's easier to work with, especially for handling many statistical analyses, such as linear models, mixed-effects models, repeated measurements or complex comparisons.

#### Task 2: Reading Delimited Data

Reading required tidyverse packages:

```{r}
library(tidyverse)
```

##### Glass Data

Reading in the glass data as a `tibble` from the given url. Based on the url, the data is delimited by `,` . So `read_csv()` can be used directly.

```{r}
#Creating a column names vector
glass_colnames <- c("ID","RI", "Na", "Mg", "Al", "Si", "K", "Ca", "Ba", "Fe", "Type")

#Reading the data from url
glass_data <- read_csv("https://www4.stat.ncsu.edu/~online/datasets/glass.data",col_names = glass_colnames)
glass_data
```

Reprocessing the `Type` column in `glass_data` with descriptive character strings. The column can be performed using the `mutate()` function from `dplyr` . Within `mutate`, applying `case_when` , which is a vectorized `if_else()` operator and works by evaluating each condition sequentially.

```{r}
glass_data_reprocessed <- glass_data |>
  mutate(Type = case_when(
    Type == 1~"building_windows_float_processed",
    Type == 2~"building_windows_non_float_processed",
    Type == 3~"vehicle_windows_float_processed",
    Type == 4~"vehicle_windows_non_float_processed",
    Type == 5~"containers",
    Type == 6~"tableware",
    Type == 7~"headlamps"))

#Preview
glass_data_reprocessed
```

Returning filtered subset `glass_data_filtered` with `Fe` less than 0.2 and is of `type` "tableware" or "headlamps" by adding `filter()` to the chain.

```{r}
glass_data_filtered <- glass_data |>
  mutate(Type = case_when(
    Type == 1~"building_windows_float_processed",
    Type == 2~"building_windows_non_float_processed",
    Type == 3~"vehicle_windows_float_processed",
    Type == 4~"vehicle_windows_non_float_processed",
    Type == 5~"containers",
    Type == 6~"tableware",
    Type == 7~"headlamps")) |>
  filter(Type %in% c("tableware","headlamps"),Fe < 0.2)
glass_data_filtered
```

##### Yeast Data

Reading in the glass data as a `tibble` from the given url. Based on the url, the data is delimited by " " (double space) . So `read_delim()` is used.

```{r}
#Creating a column names vector
yeast_colnames <- c("seq_name","mcg", "gvh", "alm", "mit", "erl", "pox", "vac", "nuk", "class")

#Reading the data from url
yeast_data <- read_delim("https://www4.stat.ncsu.edu/~online/datasets/yeast.data",delim = "  ",col_names = yeast_colnames, show_col_types = TRUE)
yeast_data
```

Excluding `seq_name` and `nuk` columns from `yeast_data` using `select()`.

```{r}
#Selecting columns to exclude using -c()
yeast_data_filtered <- yeast_data |>
  select(-c(seq_name,nuk))
yeast_data_filtered
```

Grouping the yeast_data by `class` within the chain and creating new columns using `mutate()` . Within mutate, applying the mean and median for each numerical variable with `across()` .

```{r}
yeast_data_processed <- yeast_data |>
  select(-c(seq_name,nuk)) |>
  group_by(class) |>
  mutate(across(c(mcg, gvh, alm, mit, erl, pox, vac), list(mean = mean, median = median), .names = "{.fn}_{.col}"))
yeast_data_processed
```

#### Task 3: Combining Excel and Delimited Data

Reading the readxl data and reading the file from local directory

```{r}
library(readxl)
white_wine <- read_excel("white-wine.xlsx")
white_wine
```

Modifying the variable names using sheet 2 from `white-wine.xlsx` .

```{r}
white_wine_cols <- read_excel("white-wine.xlsx",sheet = 2)

colnames(white_wine) <- white_wine_cols$Variables
white_wine
```

Adding a column corresponding to wine type. For this all the observations are "white"

```{r}
white_wine$type <- "white"
white_wine
```

Reading the red wine dataset from `;` delimited file using `read_delim`. Then repacing the original column names with previously modified columnames used in white_wine_cols

```{r}
red_wine <- read_delim("https://www4.stat.ncsu.edu/~online/datasets/red-wine.csv", delim = ";", col_names = TRUE)

colnames(red_wine) <- white_wine_cols$Variables
red_wine
```

Adding a column corresponding to wine type. For this all the observations are "red."

```{r}
red_wine$type <- "red"
red_wine
```

Joining `red_wine` and `white_wine` to obtain `wine_df` using `bind_rows()` .

```{r}
wine_df <- bind_rows(red_wine,white_wine)
wine_df
```

Filtering `wine_df` with `quality` \> 6.5 and `alcohol` \< 132.

```{r}
wine_df |>
  filter(quality > 6.5 & alcohol < 132)
```

Sorting the data by quality in descending order using `arrange(desc())` .

```{r}
wine_df |>
  filter(quality > 6.5 & alcohol < 132) |>
  arrange(desc(quality))
```

selecting the columns `acid`, `alcohol`, `type` and `quality` using `select()` .

```{r}
wine_df |>
  filter(quality > 6.5 & alcohol < 132) |>
  arrange(desc(quality)) |>
  select(contains("acid"),c(alcohol, type, quality))
```

Obtaining mean and standard deviation of `alcohol` grouped by quality using `group_by()` and `mutate(across())` as used previously.

```{r}
wine_df |>
  filter(quality > 6.5 & alcohol < 132) |>
  arrange(desc(quality)) |>
  select(contains("acid"),c(alcohol, type, quality)) |>
  group_by(quality) |>
  mutate(across(alcohol,list(mean = mean,sd = sd),.names = "{.col}_{.fn}"))
```

#### Task 4: Database Practice

Reading the necessary packages for database connections.

```{r}
#Reading the packages
library(DBI)
library(RSQLite)
con <- dbConnect(RSQLite::SQLite(), "lahman.db")
```

Showing all the tables in the `lahman.db` .

```{r}
dbListTables(con)
```

Returning all data from `Teams` table using `tbl()` .

```{r}
tbl(con,"Teams") |>
  filter(yearID == 2015)
```

Returning all data from `Teams` table using `SQL` query.

```{r}
tbl(con, sql(
"SELECT *
FROM `Teams`
WHERE (`yearID` = 2015)")
)
```

Returning hall of fame players, the nomination year and category from `HallOfFame`

```{r}
tbl(con, sql(
"SELECT `playerID`, `yearID`, `category`
FROM `HallOfFame`
WHERE `inducted` = 'Y'
"))
```

Performing inner join using `inner_join()` by `playerID` to obtain `nameLast` and `nameFirst` for associated inductees. This constructs a table with People in Hall of Fame.

```{r}
inner_join(tbl(con, sql(
"SELECT `playerID`, `yearID`, `category`
FROM `HallOfFame`
WHERE `inducted` = 'Y'
")),
tbl(con, sql(
  "SELECT `nameFirst`,`nameLast`,`playerID`
  FROM `People`
  ")),by = join_by(playerID == playerID)) |>
  collect()
```

Selecting `playerID`, `G`, `W` and `L` columns from the `Managers`. Then grouping the data by `playerID`, calculates the sum of `G`, `W` and `L`, and storing the results as `G_managed`, `Total_W`, and `Total_L` respectively. This obtains an overall record for `playerID` with at least one match as a manager. Then creating a new column `Win_percent` by dividing `Total_W` by `G_managed` and arranging in descending order based on it. This constructs a table with Managerial record (at least managed one game)

```{r}
tbl(con, "Managers") |>
  select(playerID, G,W,L) |>
  group_by(playerID) |>
  summarize(G_managed = sum(G, na.rm = TRUE),
Total_W = sum(W, na.rm = TRUE),
Total_L = sum(L, na.rm = TRUE)) |>
  collect() |>
  mutate(
    Win_percent = Total_W/G_managed) |>
  arrange(desc(Win_percent))
```

Performing inner join on newly created hall of fame people with managerial record table to yield a table that shows hall of fame inductees with at least 1 game as a manager under their belt. This includes their personal and managerial record as well.

```{r}
inner_join(
  inner_join(tbl(con, sql(
"SELECT `playerID`, `yearID`, `category`
FROM `HallOfFame`
WHERE `inducted` = 'Y'
")),
tbl(con, sql(
  "SELECT `nameFirst`,`nameLast`,`playerID`
  FROM `People`
  ")),by = join_by(playerID == playerID)) |>
  collect(),
tbl(con, "Managers") |>
  select(playerID, G,W,L) |>
  group_by(playerID) |>
  summarize(G_managed = sum(G, na.rm = TRUE),
Total_W = sum(W, na.rm = TRUE),
Total_L = sum(L, na.rm = TRUE)) |>
  collect() |>
  mutate(
    Win_percent = Total_W/G_managed) |>
  arrange(desc(Win_percent)),by = join_by(playerID == playerID)) |>
  collect() |>
  arrange(desc(Win_percent))
```
